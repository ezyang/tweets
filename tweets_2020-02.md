RT @nelhage: I wrote some thoughts on software performance: https://blog.nelhage.com/post/reflections-on-performance/

(Originally on Twitter: [Mon Feb 03 02:43:46 +0000 2020](https://twitter.com/ezyang/status/1224161526074028033))
----
@EremondiJoey Proof relevance matters here because Bot -&gt; Bot can be implemented with both absurd and with id

(Originally on Twitter: [Thu Feb 06 23:37:46 +0000 2020](https://twitter.com/ezyang/status/1225564270877925378))
----
@jseakle Running out of vp tokens ends the game right?

(Originally on Twitter: [Thu Feb 06 23:41:59 +0000 2020](https://twitter.com/ezyang/status/1225565330644361217))
----
I never would have predicted that my internal Haskell type checker would be so useful for debugging C++ type errors

(Originally on Twitter: [Tue Feb 11 19:19:28 +0000 2020](https://twitter.com/ezyang/status/1227311204365950976))
----
@luqui Just the general idea of having a type checker in your head, and then running it manually and comparing with what the computer is telling you

(Originally on Twitter: [Tue Feb 11 20:47:24 +0000 2020](https://twitter.com/ezyang/status/1227333336043048962))
----
@luqui @unisonweb When you don't need to branch types, this is called "feature flags"

(Originally on Twitter: [Tue Feb 11 21:12:35 +0000 2020](https://twitter.com/ezyang/status/1227339673607065602))
----
You are designing a PL which distinguishes between pure and impure functions, but you cannot stop users from writing impure code inside pure functions (think FFI). Do you default to assuming functions are pure or impure?

(Originally on Twitter: [Wed Feb 12 16:59:46 +0000 2020](https://twitter.com/ezyang/status/1227638435239931904))
----
@whyevernotso Purity of the computation helps the optimizer determine what permissible and unpermissible optimizations are.

(Originally on Twitter: [Wed Feb 12 18:06:32 +0000 2020](https://twitter.com/ezyang/status/1227655240394080256))
----
@sigkill_dk @whyevernotso I dunno, do you want to write a C++ function optimizer? :&gt;

(Originally on Twitter: [Wed Feb 12 19:07:57 +0000 2020](https://twitter.com/ezyang/status/1227670696714784769))
----
There’s premature optimization, and then there’s not doing dumb shit

(Originally on Twitter: [Wed Feb 12 23:53:15 +0000 2020](https://twitter.com/ezyang/status/1227742491643973633))
----
@mattmight @webyrd Oh my god how long does this go

(Originally on Twitter: [Thu Feb 13 03:59:10 +0000 2020](https://twitter.com/ezyang/status/1227804381678055431))
----
RT @sigfpe: There's a numerical method "design pattern" I've seen many times but I've never seen pointed out explicitly. So here goes. The…

(Originally on Twitter: [Sat Feb 15 18:15:27 +0000 2020](https://twitter.com/ezyang/status/1228744647104778241))
----
Is a big benefit of nanopass compilers easier onboarding and coordination when developing on the compiler?

(Originally on Twitter: [Tue Feb 18 21:16:04 +0000 2020](https://twitter.com/ezyang/status/1229877262830522371))
----
I have a pointer whose address is 0x5555ffff0000 this is obviously wrong right???

(Originally on Twitter: [Wed Feb 19 17:08:30 +0000 2020](https://twitter.com/ezyang/status/1230177349691432962))
----
We have a program that gets 5% faster when you replace C11 relaxed atomic_load with a load from a volatile variable. What could the difference be coming from? (w/ @colesbury) (perhaps cc @johnregehr?)

(Originally on Twitter: [Thu Feb 20 18:54:35 +0000 2020](https://twitter.com/ezyang/status/1230566434675163139))
----
@colesbury @johnregehr C11 relaxed atomic_load produces one extra load than the volatile variable (which is a fused compare with memory operand), but the cycle counts should be the same, and we don't think that we are bottlenecked on instruction decoding...

(Originally on Twitter: [Thu Feb 20 18:55:17 +0000 2020](https://twitter.com/ezyang/status/1230566609179303936))
----
@OswaldChocolate @colesbury @johnregehr Only a *compiler* memory barrier, right? On x86, shouldn't be any difference in instructions.

(Originally on Twitter: [Thu Feb 20 19:16:24 +0000 2020](https://twitter.com/ezyang/status/1230571925010866180))
----
RT @trav_downs: @ezyang @colesbury @johnregehr That's your answer, I think? Fused load/cmp is better (faster) than separate (and not just a…

(Originally on Twitter: [Thu Feb 20 19:53:26 +0000 2020](https://twitter.com/ezyang/status/1230581245140185089))
----
RT @trav_downs: @ezyang @colesbury @johnregehr In principle, relaxed atomic loads can be better optimized than volatile: they can be reorde…

(Originally on Twitter: [Thu Feb 20 19:54:00 +0000 2020](https://twitter.com/ezyang/status/1230581388585267200))
----
@colesbury @johnregehr (I forgot to mention, but most people assumed right: this is on x86_64)

(Originally on Twitter: [Thu Feb 20 20:18:56 +0000 2020](https://twitter.com/ezyang/status/1230587661078974464))
----
@trav_downs @colesbury @johnregehr I suppose there is a logical follow up question, which is whether or not fused load/cmp is correct assembly for the relaxed atomic load.

(Originally on Twitter: [Thu Feb 20 20:20:02 +0000 2020](https://twitter.com/ezyang/status/1230587936955129857))
----
RT @trav_downs: @ezyang @colesbury @johnregehr Yes. Logically it is equivalent to separate load and cmp, and there are no changes in the at…

(Originally on Twitter: [Thu Feb 20 20:25:27 +0000 2020](https://twitter.com/ezyang/status/1230589302293356547))
----
What is the pseudoinverse of two stacked identity matrices? Inquiring minds want to know!

(Originally on Twitter: [Fri Feb 21 17:21:47 +0000 2020](https://twitter.com/ezyang/status/1230905470161997825))
----
Inverse computation is just reverse mode AD but instead of summing you require all branches to invert to the same function.

(Originally on Twitter: [Fri Feb 21 17:38:50 +0000 2020](https://twitter.com/ezyang/status/1230909757868912640))
----
RT @colesbury: @trav_downs @ezyang @johnregehr What other ways is it faster? My current guess is that the extra register with non-fused loa…

(Originally on Twitter: [Fri Feb 21 19:50:53 +0000 2020](https://twitter.com/ezyang/status/1230942990727774214))
----
RT @colesbury: @trav_downs @ezyang @johnregehr In isolation, the difference between fused and unfused mov/cmp seems quite small:

https://t…

(Originally on Twitter: [Fri Feb 21 19:50:55 +0000 2020](https://twitter.com/ezyang/status/1230942998126563328))
----
RT @trav_downs: @colesbury @ezyang @johnregehr It is one less uop, so it is faster in all the ways that say removing a 1 uop instruction wo…

(Originally on Twitter: [Sat Feb 22 18:03:08 +0000 2020](https://twitter.com/ezyang/status/1231278264431321088))
----
RT @trav_downs: @colesbury @ezyang @johnregehr In fact, I never even thought of it as much of a decode benefit: IIRC it actually causes som…

(Originally on Twitter: [Sat Feb 22 18:03:11 +0000 2020](https://twitter.com/ezyang/status/1231278275005239297))
----
RT @trav_downs: @colesbury @ezyang @johnregehr ... group to make this happen. I don't know all the details there though.

The best case for…

(Originally on Twitter: [Sat Feb 22 18:03:13 +0000 2020](https://twitter.com/ezyang/status/1231278285218250753))
----
RT @trav_downs: @colesbury @ezyang @johnregehr So in that case, a loop that drops from 7 to 6 uops due to macro fusion sees a 33% boost!

O…

(Originally on Twitter: [Sat Feb 22 18:03:18 +0000 2020](https://twitter.com/ezyang/status/1231278303727804422))
----
RT @trav_downs: @colesbury @ezyang @johnregehr This is also a good example because it involves the LSD (mostly disabled on all Skylake-like…

(Originally on Twitter: [Sat Feb 22 18:03:21 +0000 2020](https://twitter.com/ezyang/status/1231278316667260929))
----
RT @trav_downs: @colesbury @ezyang @johnregehr Well the first example had a 19% throughput increase, but your numbers, which seems fairly s…

(Originally on Twitter: [Sat Feb 22 18:03:26 +0000 2020](https://twitter.com/ezyang/status/1231278338095960064))
----
RT @trav_downs: @colesbury @ezyang @johnregehr ... "cheapest" uop at that (one that can go to all 4 ALUs, and has 1 cycle latency). So the…

(Originally on Twitter: [Sat Feb 22 18:03:29 +0000 2020](https://twitter.com/ezyang/status/1231278351186300928))
----
RT @trav_downs: @colesbury @ezyang @johnregehr It's hard to say much in general about actual performance improvement, because low-level ana…

(Originally on Twitter: [Sat Feb 22 18:03:32 +0000 2020](https://twitter.com/ezyang/status/1231278363542728704))
----
RT @trav_downs: @colesbury @ezyang @johnregehr ... about the actual performance impact in-situ without a lot more details.

A note about la…

(Originally on Twitter: [Sat Feb 22 18:03:35 +0000 2020](https://twitter.com/ezyang/status/1231278375274188808))
----
RT @trav_downs: @colesbury @ezyang @johnregehr ... may carry a dependency, but its latency of 1 isn't affected by macro fusion.

Macro fusi…

(Originally on Twitter: [Sat Feb 22 18:03:37 +0000 2020](https://twitter.com/ezyang/status/1231278385680220160))
----
RT @trav_downs: @colesbury @ezyang @johnregehr It is actually possible for macro fusion to affect latency negatively, too!

The fused uop i…

(Originally on Twitter: [Sat Feb 22 18:03:40 +0000 2020](https://twitter.com/ezyang/status/1231278397793480704))
----
RT @trav_downs: @colesbury @ezyang @johnregehr ... to the op itself.

In the case the op is part of a critical chain and there is imperfect…

(Originally on Twitter: [Sat Feb 22 18:03:43 +0000 2020](https://twitter.com/ezyang/status/1231278408618979328))
----
RT @trav_downs: @colesbury @ezyang @johnregehr These days, of course, the primary downside of macro-fusion on Intel, is that they extend th…

(Originally on Twitter: [Sat Feb 22 18:03:46 +0000 2020](https://twitter.com/ezyang/status/1231278421025705985))
----
RT @trav_downs: @colesbury @ezyang @johnregehr I.e., rather than a 2 byte conditional jump with a ~6% chance of being affected by a 32-byte…

(Originally on Twitter: [Sat Feb 22 18:03:49 +0000 2020](https://twitter.com/ezyang/status/1231278433897996289))
----
So basically, to write a correct set of static initializers indifferent to ordering, you have to design an abelian group (destructors!)

(Originally on Twitter: [Mon Feb 24 20:00:08 +0000 2020](https://twitter.com/ezyang/status/1232032483014828033))
----
@MarisaVeryMoe Checkpointing is pretty common in deep learning, e.g., https://pytorch.org/docs/stable/checkpoint.html

(Originally on Twitter: [Tue Feb 25 23:17:44 +0000 2020](https://twitter.com/ezyang/status/1232444596661043201))
----
@MarisaVeryMoe But I feel like you were already aware of this ;)

(Originally on Twitter: [Tue Feb 25 23:18:34 +0000 2020](https://twitter.com/ezyang/status/1232444808230100993))
----
